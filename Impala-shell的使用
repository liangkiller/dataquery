#建立测试文件夹
hdfs dfs -mkdir -p /user/cloudera/sample_data/tab1 /user/cloudera/sample_data/tab2

#数据源csv
vi tab1.csv
----
1,true,123.123,2012-10-24 08:55:00
2,false,1243.5,2012-10-25 13:40:00
3,false,24453.325,2008-08-22 09:33:21.123
4,false,243423.325,2007-05-12 22:32:21.33454
5,true,243.325,1953-04-22 09:11:33
====
vi tab2.csv
----
1,true,12789.123
2,false,1243.5
3,false,24453.325
4,false,2423.3254
5,true,243.325
60,false,243565423.325
70,true,243.325
80,false,243423.325
90,true,243.325
====
#上传到hdfs
$ hdfs dfs -put tab1.csv /user/cloudera/sample_data/tab1
$ hdfs dfs -put tab2.csv /user/cloudera/sample_data/tab2
$ hdfs dfs -ls /user/cloudera/sample_data/tab1

#修改属主
$ sudo -u hdfs hadoop fs -chown -R impala:supergroup /user/cloudera/
#修改hive.metastore.warehouse.dir属主
$ sudo -u hdfs hadoop fs -chown -R impala:supergroup /opt/hive/

#v进入impala-shell
$ sudo -u hdfs impala-shell
#Impala和Hive共用metastore数据库中表的元数据信息
#impala需要同步hive操作的元数据，hive会自动同步impala的操作
#同步元数据
>INVALIDATE METADATA;
#建立3个表
----
DROP TABLE IF EXISTS tab1;
-- The EXTERNAL clause means the data is located outside the central location
-- for Impala data files and is preserved when the associated Impala table is dropped.
-- We expect the data to already exist in the directory specified by the LOCATION clause.
CREATE EXTERNAL TABLE tab1
(
   id INT,
   col_1 BOOLEAN,
   col_2 DOUBLE,
   col_3 TIMESTAMP
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/user/cloudera/sample_data/tab1';

DROP TABLE IF EXISTS tab2;
-- TAB2 is an external table, similar to TAB1.
CREATE EXTERNAL TABLE tab2
(
   id INT,
   col_1 BOOLEAN,
   col_2 DOUBLE
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/user/cloudera/sample_data/tab2';

DROP TABLE IF EXISTS student;
CREATE TABLE student
(
   id INT,
   name STRING
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
====

空表，存储位置就是 hive 的 hive.metastore.warehouse.dir
因为Impala是对hive的优化，所以impala的数据是直接存在hive上的，确保impala有对 hive.metastore.warehouse.dir 的写权限，如果没有就把impala加到hive这个组里面

----
select * from tab1;
====

调用写好的.sql文件
vi customer_setup.sql
----
create database tpcds;
use tpcds;

drop table if exists customer;
create external table customer
(
    c_customer_sk             int,
    c_customer_id             string,
    c_current_cdemo_sk        int,
    c_current_hdemo_sk        int,
    c_current_addr_sk         int,
    c_first_shipto_date_sk    int,
    c_first_sales_date_sk     int,
    c_salutation              string,
    c_first_name              string,
    c_last_name               string,
    c_preferred_cust_flag     string,
    c_birth_day               int,
    c_birth_month             int,
    c_birth_year              int,
    c_birth_country           string,
    c_login                   string,
    c_email_address           string,
    c_last_review_date        string
)
row format delimited fields terminated by '|'
location '/user/hive/tpcds/customer.dat';
====
#执行
$ sudo -u hdfs impala-shell -i localhost -f customer_setup.sql
$ sudo -u hdfs
Impala支持 insert into ...values...这样的单条插入
可以向外部分区表插入数据
$ hdfs dfs -mkdir -p /user/impala/data/logs/year=2015/month=01/day=01/host=host1
$ hdfs dfs -mkdir -p /user/impala/data/logs/year=2015/month=02/day=22/host=host2
vi a.txt
----
1,jack
2,michael
====
vi b.txt
----
3,sara
4,john
====
hdfs dfs -put /root/a.txt /user/impala/data/logs/year=2015/month=01/day=01/host=host1
hdfs dfs -put /root/b.txt /user/impala/data/logs/year=2015/month=02/day=22/host=host2

#创建外部分区表
----
create external table logs (id int, name string)
  partitioned by (year string, month string, day string, host string)
  row format delimited fields terminated by ','
  location '/user/impala/data/logs';
====
#手动添加这两个分区
----
alter table logs add partition (year="2015",month="01",day="01",host="host1");
alter table logs add partition (year="2015",month="02",day="22",host="host2");
====
#查询
select * from logs
#插入一条数据
insert into logs partition (year="2015", month="01", day="01", host="host1") values (6,"ted");
select * from logs;

参考链接：
https://blog.csdn.net/nsrainbow/article/details/43243389
